{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62d4935-31c5-4c2f-aec3-9ac7eb5bd0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c65eed8-f9fb-4955-84e1-885ce0c8367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw from the prior\n",
    "u_1 = np.random.uniform(0,1)\n",
    "u_2 = np.random.uniform(0,1)\n",
    "# gamma + alpha = 1 - u_1\n",
    "gamma = u_2 * (1 - u_1) / 2 # ensure that alpha > gamma\n",
    "alpha = (1 - u_1) - gamma\n",
    "beta = u_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd21043d-7e19-40ff-99d3-f6a9de820868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07536668596951239, 0.09568824157375029, 0.8289450724567373)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ec532c-7abb-45bd-9464-e0cac25b520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_statistic(cluster_df):\n",
    "    g = len(cluster_df['Cluster Size'])\n",
    "    sum_population = (cluster_df['Cluster Size'] * cluster_df['Number of Clusters']).sum()\n",
    "    y1 = g / sum_population\n",
    "    y2 = 1 - ((cluster_df['Number of Clusters'] / sum_population) ** 2).sum()\n",
    "    return np.array([y1, y2])\n",
    "\n",
    "\n",
    "def subsample_population(population_df, subsample_size=473):\n",
    "    # Expand the population DataFrame into individual bacteria\n",
    "    expanded_population = population_df.loc[\n",
    "        population_df.index.repeat(population_df['count'])\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    # Randomly subsample\n",
    "    subsample = expanded_population.sample(n=subsample_size, replace=False)\n",
    "\n",
    "    # Reconstruct the subsample cluster sizes\n",
    "    subsample_cluster_sizes = subsample.groupby('genotype').size()\n",
    "\n",
    "    # Convert back to a DataFrame\n",
    "    cluster_df = subsample_cluster_sizes.value_counts().reset_index()\n",
    "    cluster_df.columns = ['Cluster Size', 'Number of Clusters']\n",
    "\n",
    "    return cluster_df\n",
    "\n",
    "\n",
    "def simulate_data(alpha, beta, gamma):\n",
    "    N_target = 1e4  # Target population size\n",
    "\n",
    "    # Initialize population\n",
    "    population = {0: 1}  # Start with one bacterium of genotype 0\n",
    "    N = 1  # Current population size\n",
    "    time = 0  # Simulation time\n",
    "    times = [0]  # Record times\n",
    "    sizes = [1]  # Record total population sizes\n",
    "\n",
    "    # Simulation loop\n",
    "    while N < N_target:\n",
    "        # Compute total rate\n",
    "        rates = {genotype: (alpha + gamma + beta) * count for genotype, count in population.items()}\n",
    "        total_rate = sum(rates.values())\n",
    "\n",
    "        # If total rate is zero, population is extinct\n",
    "        if total_rate == 0 or N == 0:\n",
    "            print('extinct!!')\n",
    "            return np.array([0, 1])  # Return default summary statistic\n",
    "\n",
    "        # Sample time to next event\n",
    "        delta_t = np.random.exponential(1 / total_rate)\n",
    "        time += delta_t\n",
    "\n",
    "        # Determine which event occurs\n",
    "        event = np.random.uniform(0, total_rate)\n",
    "        cumulative_rate = 0\n",
    "        for genotype, rate in rates.items():\n",
    "            cumulative_rate += rate\n",
    "            if event < cumulative_rate:\n",
    "                selected_genotype = genotype\n",
    "                break\n",
    "\n",
    "        # Determine event type (replication, death, mutation)\n",
    "        event_type = np.random.choice(['replication', 'death', 'mutation'],\n",
    "                                      p=[alpha, gamma, beta])\n",
    "        if event_type == 'replication':\n",
    "            population[selected_genotype] += 1\n",
    "            N += 1\n",
    "        elif event_type == 'death':\n",
    "            population[selected_genotype] -= 1\n",
    "            if population[selected_genotype] == 0:\n",
    "                del population[selected_genotype]\n",
    "            N -= 1\n",
    "        elif event_type == 'mutation':\n",
    "            population[selected_genotype] -= 1\n",
    "            if population[selected_genotype] == 0:\n",
    "                del population[selected_genotype]\n",
    "            # Create new genotype\n",
    "            new_genotype = max(population.keys(), default=0) + 1\n",
    "            population[new_genotype] = 1\n",
    "\n",
    "        # Record data\n",
    "        times.append(time)\n",
    "        sizes.append(N)\n",
    "\n",
    "    # Create population DataFrame\n",
    "    population_df = pd.DataFrame(\n",
    "        population.items(),\n",
    "        columns=['genotype', 'count']\n",
    "    )\n",
    "\n",
    "    cluster_df = subsample_population(population_df)\n",
    "    y = summary_statistic(cluster_df)\n",
    "    \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447bf457-6abc-4e2c-b110-b2c529c84b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given data\n",
    "cluster_sizes = [1, 2, 3, 4, 5, 8, 10, 15, 23, 30]\n",
    "number_of_clusters = [282, 20, 13, 4, 2, 1, 1, 1, 1, 1]\n",
    "\n",
    "\n",
    "true_cluster_df = pd.DataFrame({\n",
    "    'Cluster Size': cluster_sizes,\n",
    "    'Number of Clusters': number_of_clusters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2aad2f-2f03-42e6-8247-adce18c6e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_summary_statistics = summary_statistic(true_cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3baec56a-7cec-42f8-842c-74b25b6ff82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02114165, 0.64189712])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_summary_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f853b104-f2ff-4393-9121-6f8f77d0f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def ABC_sampler(epsilon, true_summary_statistics):\n",
    "    # Multivariate Gaussian parameters\n",
    "    mean = [0.6, 0.2]\n",
    "    cov = [[0.007, -0.008], [-0.008, 0.01]]\n",
    "\n",
    "    while True:\n",
    "        alpha, gamma = np.random.multivariate_normal(mean, cov)\n",
    "        if alpha > 0 and gamma > 0 and alpha + gamma < 1 and alpha > gamma :\n",
    "            break\n",
    "    beta = 1 - alpha - gamma\n",
    "    statistic_proposal = simulate_data(alpha, beta, gamma)\n",
    "    distance = np.linalg.norm(statistic_proposal - true_summary_statistics, ord=2)\n",
    "    proposal_pdf = multivariate_normal.pdf([alpha, gamma], mean=mean, cov=cov)\n",
    "    weight = 1 / proposal_pdf\n",
    "    \n",
    "    if distance <= epsilon: \n",
    "        zero_weight = False\n",
    "    else:\n",
    "        zero_weight = True\n",
    "    return alpha, gamma, weight, zero_weight, statistic_proposal, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07077c-0c7d-4993-9309-ac4208cce3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 180/50000 [00:46<4:46:17,  2.90it/s]"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import tqdm\n",
    "\n",
    "n_samples = 50000\n",
    "epsilon = 0.2\n",
    "\n",
    "\n",
    "def worker(_):\n",
    "    return ABC_sampler(epsilon, true_summary_statistics)\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(worker)(i) for i in tqdm.tqdm(range(n_samples)))\n",
    "\n",
    "# Unpack results\n",
    "alphas, gammas, weights, zero_weights, statistic_proposals, distances = zip(*[(alpha, gamma, weight, zero_weights, statistic_proposal, distance) for alpha, gamma, weight, zero_weights, statistic_proposal, distance in results])\n",
    "\n",
    "# Convert to lists (optional)\n",
    "alphas = list(alphas)\n",
    "gammas = list(gammas)\n",
    "weights = list(weights)\n",
    "zero_weights = list(zero_weights)\n",
    "statistic_proposals = list(statistic_proposals)\n",
    "distances = list(distances)\n",
    "\n",
    "print(\"Sampling completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ecfa60-d03e-484f-b28c-3a3b26678233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "results = {\n",
    "    'alphas': alphas,\n",
    "    'gammas': gammas,\n",
    "    'weights': weights,\n",
    "    'zero_weights': zero_weights,\n",
    "    'summary_satistics' : statistic_proposals,\n",
    "    'distance' : distances,\n",
    "}\n",
    "\n",
    "# Save to a pkl file\n",
    "with open('abc_results.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "print(\"Results saved to abc_results.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
